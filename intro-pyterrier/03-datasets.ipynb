{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTerrier\n",
    "\n",
    "_IN4325: Information retrieval lecture, TU Delft_\n",
    "\n",
    "**Part 3: Datasets**\n",
    "\n",
    "This notebook focuses on IR datasets and pre-made indexes that can be loaded automatically in PyTerrier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets\n",
    "\n",
    "PyTerrier comes with a multitude of datasets that can be loaded directly. This is great because the parsing is already taken care of and any required files will be downloaded automatically.\n",
    "\n",
    "A list of available datasets can be found [here](https://pyterrier.readthedocs.io/en/latest/datasets.html#available-datasets) or by calling the following function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.datasets.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset has the following components:\n",
    "\n",
    "- Corpus (the documents),\n",
    "- index (pre-made, ready to use),\n",
    "- topics (queries or topic descriptions, grouped in folds or splits),\n",
    "- qrels (query relevance information, we'll use this for evaluation in an upcoming notebook).\n",
    "\n",
    "Note that, for many datasets, some of these components are missing. Furthermore, the prefix `irds:` denotes that the corresponding dataset is loaded from the [`ir_datasets`](https://ir-datasets.com/) library, which seamlessly integrates with PyTerrier.\n",
    "\n",
    "Let's start by loading the `vaswani` dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"vaswani\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, there are pre-made indexes available that we can load. In order to do this, we need to select a _variant_. The variants differ slightly, for example, in terms of pre-processing. An overview of the indexes and variants can be found in the [Terrier data repository](http://data.terrier.org/).\n",
    "\n",
    "We'll use the standard variant, `terrier_stemmed`, to create a BM25 model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = dataset.get_index(variant=\"terrier_stemmed\")\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "bm25.search(\"computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a retriever directly from the dataset like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve.from_dataset(dataset, variant=\"terrier_stemmed\", wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also browse the corpus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in dataset.get_corpus_iter():\n",
    "    print(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the topics (queries) can be accessed as a `pandas.DataFrame`, such that we can use them directly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25(dataset.get_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some datasets require a variant here, such as `variant=\"train\"`.\n",
    "\n",
    "Since the corpus iterator already yields the documents in the correct format (see part 2: indexing), we can use it directly to create our own index if we wish:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "index = pt.IterDictIndexer(\n",
    "    str(Path.cwd()),  # this will be ignored\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ").index(dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Check out the [datasets section](https://pyterrier.readthedocs.io/en/latest/datasets.html) in the documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
